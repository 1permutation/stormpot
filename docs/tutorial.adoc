:examples: ../src/test/java/stormpot/examples

== Tutorial

This tutorial assumes no prior understanding of object pooling, and will introduce the concept bit by bit.
The aim is to gradually build up knowledge about object pooling in general, when to use pooling, and how to pool objects with Stormpot specifically.

=== What is an Object Pool?

An object pool is a homogenous collection of objects.
Whenever one such object is needed for something, it is taken from the pool, instead of being allocated anew.
Once an object has served its purpose, it returns to the pool so that it can later be reused.
We say the collection of pooled objects is homogenous, because it does not matter which of the objects are picked to be used in a given case.
This is where pools differs from caches: in a cache, the elements are distinct, and have some identity by which they are looked up when needed.
In a pool, there is nothing to look up by, and any element will do.

The purpose of the pool, is to prevent as many allocations of the pooled objects as possible, with as little overhead as possible.
If the objects being pooled represent a limited resource, a secondary purpose of the pool, is to enforce an upper bound on the number of these objects that are in use, at any given time.

=== When Should I use an Object Pool?

Java is a garbage collected language.
Objects are allocated on a shared heap of memory.
The garbage collector provides the illusion of infinite memory, by periodically removing unused objects from the heap.
This is the most efficient way to allocate and free memory.

Most object allocations in Java are done by bumping a pointer into a thread-local allocation buffer.
This common fast-path allocation is typically just 10 native instructions.
Once the memory has been allocated, the object has to be initialised with the object initialiser, and constructed with the constructor.

Freeing memory is done in batches, called collections, following the allocation rate and the demand for new memory.
The garbage collector traces through the object graph, finding all the objects that are live and in use.
All the objects that are not live, are garbage and can be collected.
This often means that the threads of the application, the mutator threads, needs to be paused so the collector can get a consistent view of what is live and what is not.
These pauses are a necessary evil of a garbage collector.
The pause times scale with the number of live objects, not the size of the heap, so high object retention has a bigger performance impact than a high allocation rate.

An object pool cannot beat the garbage collector on throughput and latency of memory allocation and freeing, because the pool will necessarily have to do some form of synchronisation to coordinate access to its limited set of objects.
In other words, if objects are pooled for performance reasons, the cost of the object initialisation and construction must outweigh the overhead of the pool.
This leaves us with only two good cases for object pooling:

. Objects that have very expensive initialisation or construction.
. Objects that represent a limited resource, such as network connections or threads.

Java already does thread pooling with the +Executors+ framework, so this use case is solved.
This leaves network connections -- for instance to a database, or some other kind of remote service -- as the archetypical example of something you want to pool.
All other cases are better handled by the garbage collector.

=== The Elements of an Object Pool

There are three central elements to a pool, and a number of peripheral elements.
The central elements are the following:

. The objects being pooled.
  In Stormpot terms, these are a subtype of +Poolable+, and their number per pool is determined by the configured size of the given pool.
  The implementation of the +Poolable+ interface is supplied by the user code, through the +Allocator+.
. The +Allocator+ creates and destroys the objects being pooled, with the +allocate+ and +deallocate+ methods, respectively.
  There is one allocator per pool, and it is supplied to the pool through the pool configuration.
. The pool itself, which is an implementation of the +Pool+ interface.
  Implementations of this interface is supplied by the Stormpot library.
  The +BlazePool+ class is one such implementation.

The pool lets interested parties +claim+ objects as needed, and expects them to be returned via a call to the +release+ method on the +Poolable+ interface.
The +release+ method on the poolable works by delegating to a +Slot+ object that was given to the poolable, through the allocator, when the poolable was created.
It is the job of the pool to turn as many calls to +claim+ and +release+ into as few calls to +allocate+ and +deallocate+ as possible.
The pool has to do this with the smallest overhead possible, and while observing the configured upper bound on the number of objects.

The pool has a background thread dedicated to allocating and deallocating the poolable objects, because these are presumably expensive operations.
This way, the threads that come to the pool to claim objects, don't have to pay the cost of allocating those objects.
This reduces the latency for claim in the general case.

In essence, the central parts of the pool fit together like this:

[ditaa]
----
+-------------+                claim>              +------------------------+
|             +----------------------------------->+                        |
|  User code  |                                    |        BlazePool       |
|             |           +------------+   <claim  |                        |
|             |   ‹use›   |            +<----------+  +------------------+  |
|             +---------->+  Poolable  |           |  | Allocator Thread |  |
|             |           |            |           |  +--+---------------+  |
|             |  release  |  +------+  |           |     |                  |
|             +---------->+->+ Slot +--+---------->+     | allocate/        |
|             |           |  +------+  |           |     | deallocate       |
+-------------+           +------------+           |     v                  |
                                                   |  +------------------+  |
                                                   |  |    Allocator     |  |
                                                   |  +------------------+  |
                                                   +------------------------+
----

=== More Elements of Stormpot

When it comes to object pooling with Stormpot specifically, there is more to it than the three central elements of the pool, the poolable objects and the allocator.
We have already seen the slot object, and how it is used to inform the pool when an object is released.
And we have seen the dedicated allocator thread, that uses the allocator to keep the pool filled with objects.
We have also have also seen hints at the life cycle of the pooled objects: first they are allocated, then they are claimed and released a number of times, and finally they are deallocated.

There are three reasons an object can get deallocated: the object expired, the pool was resized to be smaller, or the pool was shut down.
These three situations are particular to how Stormpot works.

==== Object Expiration

Whether or not an object has expired is decided by the configured +Expiration+ strategy on every call to the claim method, for each candidate that is checked.
The +hasExpired+ method of the configured expiration is therefor very performance critical, as it may be called more than once for every call to the claim method.

You can implement and configure your own +Expiration+ implementation if you want, but Stormpot also comes with a couple of implementations of its own.
The default expiration implementation is a +TimeSpreadExpiration+ that is configured to expire objects after they have been live for somewhere between 8 and 10 minutes.
This implementation chooses the expiration age randomly on a per object bases, and thereby avoids expiring all objects at the same time.

==== Pool Resizing

A pool is configured with an initial size, through the the size property of the +Config+ object given to the pool upon construction.
However, this size is not fixed.
Both the +QueuePool+ and the +BlazePool+ implementations support dynamic resizing by implementing the +ResizablePool+ interface.
This means that their target size can be set and queried whenever desired.
Changing the size on the +Config+ object has no effect on pools that have already been constructed.

The +ResizablePool+ interface allows anyone with access to the pool instance, to grow or shrink it as they see fit.
This works by immediately setting the target pool size to the new value.
There is no way to tell when the pool will actually reach the new target size.
Once a new target size has been set, the pool will work towards it at its own pace.
The reason is that when the pool is shrunk, it cannot force objects that are currently claimed, to suddenly be released to that they can be deallocated.
Likewise, it takes time to allocate the new objects when the pool is grown.
The pool is otherwise designed to never have more objects than its target size, allocated at any one point in time.
Obviously this isn't so when the pool is in the process of shrinking towards a new smaller size.
The resizing process itself works by simply allocating more objects than are deallocated, when the pool is growing, or by deallocating more objects than are allocated, when the pool is shrinking.

==== Shutting the Pool Down

Calling the +shutdown+ method on a +LifecycledPool+ only initiates the shutdown process.
Both +QueuePool+ and +BlazePool+ implements the +LifecycledPool+ interface.
The pool is not fully shut down until all the objects in it have been deallocated.
This can take a while, since objects that are claimed and in use cannot be deallocated until they are released back to the pool, and how long this takes depends entirely on the user code.
It also means that if an object has leaked – that is, it has been claimed and then forgotten, never to be released back to the pool – then the shut down process will never complete.

The +shutdown+ method returns a +Completion+ object, that allow you to +await+ the completion of the shut down process.
The +await+ method takes a +Timeout+ object, so it doesn't wait forever, and returns boolean +true+ if the shut down process completed within the given timeout period.
This is the only way to tell whether or not the shut down process has completed.

==== Timeouts




=== Configuring Stormpot


---

NOTE: The material should be _taught_ rather than described.
Perhaps as a sequence of _lessons_, implicitly or otherwise.
See http://stevelosh.com/blog/2013/09/teach-dont-tell/
What lessons?
Basic concepts of pooling.
The idea of claiming and releasing resources.
How Pool, Poolable and Allocator fit together.
How claim and expiration fit together.
The concurrency in Stormpot: The dedicated allocator thread, and the concurrent access of the pool.
